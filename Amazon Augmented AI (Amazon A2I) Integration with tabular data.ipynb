{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Augmented AI (Amazon A2I) integration with Tabular Data [Example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "    1. [Workteam](#Workteam)\n",
    "    2. [Permissions](#Notebook-Permission)\n",
    "3. [Client Setup](#Client-Setup)\n",
    "4. [Create Control Plane Resources](#Create-Control-Plane-Resources)\n",
    "    1. [Create Human Task UI](#Create-Human-Task-UI)\n",
    "    2. [Create Flow Definition](#Create-Flow-Definition)\n",
    "5. [Starting Human Loops](#Scenario-1-:-When-Activation-Conditions-are-met-,-and-HumanLoop-is-created)\n",
    "    1. [Wait For Workers to Complete Task](#Wait-For-Workers-to-Complete-Task)\n",
    "    2. [Check Status of Human Loop](#Check-Status-of-Human-Loop)\n",
    "    3. [View Task Results](#View-Task-Results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Amazon Augmented AI (Amazon A2I) makes it easy to build the workflows required for human review of ML predictions. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers. \n",
    "\n",
    "You can create your own workflows for ML models built on Amazon SageMaker or any other tools. Using Amazon A2I, you can allow human reviewers to step in when a model is unable to make a high confidence prediction or to audit its predictions on an on-going basis. \n",
    "\n",
    "Learn more here: https://aws.amazon.com/augmented-ai/\n",
    "\n",
    "In this tutorial, we will show how you can use **Amazon A2I with Tabular data.** Tabular data is the most common form of data used by data scientists today for generating models. Use cases include, fraud detection, building customer propensity models, forecasting sales using regression etc. In many cases, data scientists often convert unstructured data such as text or images into structured tables that they then use for training models. \n",
    "\n",
    "Here we will first train a model and use the outputs of the trained model to build a human loop for review.\n",
    "\n",
    "For more in depth instructions, visit https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate Amazon A2I into your human review workflows, you need three resources:\n",
    "\n",
    "* A **worker task template** to create a worker UI. The worker UI displays your input data, such as documents or images, and instructions to workers. It also provides interactive tools that the worker uses to complete your tasks. For more information, see https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-instructions-overview.html\n",
    "\n",
    "* A **human review workflow**, also referred to as a flow definition. You use the flow definition to configure your human workforce and provide information about how to accomplish the human review task. You can create a flow definition in the Amazon Augmented AI console or with Amazon A2I APIs. To learn more about both of these options, see https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html\n",
    "\n",
    "* A **human loop** to start your human review workflow. When you use one of the built-in task types, the corresponding AWS service creates and starts a human loop on your behalf when the conditions specified in your flow definition are met or for each object if no conditions were specified. When a human loop is triggered, human review tasks are sent to the workers as specified in the flow definition.\n",
    "\n",
    "When using a custom task type, as this tutorial will show, you start a human loop using the Amazon Augmented AI Runtime API. When you call `start_human_loop()` in your custom application, a task is sent to human reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Latest SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached pip-20.3.1-py2.py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.4\n",
      "    Uninstalling pip-20.2.4:\n",
      "      Successfully uninstalled pip-20.2.4\n",
      "Successfully installed pip-20.3.1\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (1.16.19)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.16.35-py2.py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from boto3) (0.3.3)\n",
      "Collecting botocore<1.20.0,>=1.19.35\n",
      "  Using cached botocore-1.19.35-py2.py3-none-any.whl (7.1 MB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.35->boto3) (2.8.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.35->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.35->boto3) (1.15.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.19\n",
      "    Uninstalling botocore-1.19.19:\n",
      "      Successfully uninstalled botocore-1.19.19\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.16.19\n",
      "    Uninstalling boto3-1.16.19:\n",
      "      Successfully uninstalled boto3-1.16.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.18.179 requires botocore==1.19.19, but you have botocore 1.19.35 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.16.35 botocore-1.19.35\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (1.19.35)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore) (1.25.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We need to set up the following data:\n",
    "* `region` - Region to call A2I.\n",
    "* `BUCKET` - A S3 bucket accessible by the given role\n",
    "    * Used to store the sample images & output results\n",
    "    * Must be within the same region A2I is called from\n",
    "* `role` - The IAM role used as part of StartHumanLoop. By default, this notebook will use the execution role\n",
    "* `workteam` - Group of people to send the work to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role and Permissions\n",
    "\n",
    "The AWS IAM Role used to execute the notebook needs to have the following permissions:\n",
    "\n",
    "* SagemakerFullAccess\n",
    "* AmazonSageMakerMechanicalTurkAccess (if using MechanicalTurk as your Workforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::835034110975:role/service-role/AmazonSageMaker-ExecutionRole-20201214T091698'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "# Setting Role to the default SageMaker Execution Role\n",
    "role = get_execution_role()\n",
    "display(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-central-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "sess = sagemaker.Session() \n",
    "\n",
    "#bucket\n",
    "BUCKET = sess.default_bucket() # or use a custom bucket if you created one. \n",
    "PREFIX = 'a2i-data'\n",
    "\n",
    "#specify output path for artifacts\n",
    "OUTPUT_PATH = f's3://{BUCKET}/a2i-results'\n",
    "\n",
    "# Region \n",
    "region = boto3.session.Session().region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular data with Amazon SageMaker\n",
    "\n",
    "Before creating the template, we will load a tabular dataset, split the data into train and test, store the test data in Amazon S3, and train a machine learning model. The dataset we use is on Breast Cancer prediction and can be found here: [1] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Based on the input features, we will first train a model to detect a benign or malignant label. \n",
    "\n",
    "Once the model is trained, we will create an endpoint, and generate some model predictions. We will then create a WorkerUI to load in our immutable test dataset as a table, and dynamically modify the verify and change predictions if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>10.31</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0</td>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>...</td>\n",
       "      <td>26.68</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>10.01</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>...</td>\n",
       "      <td>12.25</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "68       1        9.029         17.33           58.79      250.5   \n",
       "181      0       21.090         26.57          142.70     1311.0   \n",
       "63       1        9.173         13.86           59.20      260.9   \n",
       "248      1       10.650         25.22           68.01      347.0   \n",
       "60       1       10.170         14.88           64.55      311.9   \n",
       "\n",
       "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "68           0.10660           0.14130         0.31300              0.04375   \n",
       "181          0.11410           0.28320         0.24870              0.14960   \n",
       "63           0.07721           0.08751         0.05988              0.02180   \n",
       "248          0.09657           0.07234         0.02379              0.01615   \n",
       "60           0.11340           0.08061         0.01084              0.01290   \n",
       "\n",
       "     mean symmetry           ...             worst radius  worst texture  \\\n",
       "68          0.2111           ...                    10.31          22.65   \n",
       "181         0.2395           ...                    26.68          33.48   \n",
       "63          0.2341           ...                    10.01          19.23   \n",
       "248         0.1897           ...                    12.25          35.19   \n",
       "60          0.2743           ...                    11.02          17.45   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "68             65.50       324.7           0.14820            0.43650   \n",
       "181           176.50      2089.0           0.14910            0.75840   \n",
       "63             65.59       310.1           0.09836            0.16780   \n",
       "248            77.98       455.7           0.14990            0.13980   \n",
       "60             69.86       368.6           0.12750            0.09866   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "68           1.25200               0.17500          0.4228   \n",
       "181          0.67800               0.29030          0.4098   \n",
       "63           0.13970               0.05087          0.3282   \n",
       "248          0.11250               0.06136          0.3409   \n",
       "60           0.02168               0.02579          0.3557   \n",
       "\n",
       "     worst fractal dimension  \n",
       "68                   0.11750  \n",
       "181                  0.12840  \n",
       "63                   0.08490  \n",
       "248                  0.08147  \n",
       "60                   0.08020  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generatedf(split_ratio):\n",
    "    \"\"\"Loads the dataset into a dataframe and generates train/test splits\"\"\"\n",
    "    data = load_breast_cancer()\n",
    "    df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "    df['label'] = data.target\n",
    "    cols = list(df.columns)\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    train, test = train_test_split(df, test_size=split_ratio, random_state=42)\n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = generatedf(0.2)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the datasets locally\n",
    "train_data.to_csv('train.csv',index = None, header=None)\n",
    "test_data.to_csv('test.csv', index = None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-central-1-835034110975/a2i-data/test/test.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data into S3\n",
    "sess.upload_data('train.csv', bucket=BUCKET, key_prefix=os.path.join(PREFIX, 'train'))\n",
    "sess.upload_data('test.csv', bucket=BUCKET, key_prefix=os.path.join(PREFIX, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "#load the train and test data filenames from Amazon S3\n",
    "s3_input_train = sagemaker.session.s3_input(s3_data='s3://{}/{}/train'.format(BUCKET, PREFIX), content_type='csv')\n",
    "s3_input_validation = sagemaker.session.s3_input(s3_data='s3://{}/{}/test/'.format(BUCKET, PREFIX), content_type='csv')\n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Deploy the model\n",
    "\n",
    "SageMaker will set up the instance types needed and copy the data over to train the model. This may take about **3** minutes to complete training. Once the model is trained, we will deploy the model as an endpoint. Again, SageMaker will set up the instance required, copy the inference image and the inference code and create a HTTPS endpoint. This may take **4-5** minutes. For more details on how SageMaker creates an endpoint, visit: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 08:44:43 Starting - Starting the training job...\n",
      "2020-12-14 08:44:44 Starting - Launching requested ML instancesProfilerReport-1607935482: InProgress\n",
      "......\n",
      "2020-12-14 08:46:07 Starting - Preparing the instances for training......\n",
      "2020-12-14 08:46:57 Downloading - Downloading input data\n",
      "2020-12-14 08:46:57 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:47:21] 455x30 matrix with 13650 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:47:21] 114x30 matrix with 3420 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 455 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 114 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.97029#011validation-auc:0.960531\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.979569#011validation-auc:0.981657\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.983304#011validation-auc:0.988536\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.988393#011validation-auc:0.989355\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.989831#011validation-auc:0.992466\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.992935#011validation-auc:0.994432\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.993038#011validation-auc:0.995906\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.993586#011validation-auc:0.995742\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.993628#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.993493#011validation-auc:0.995742\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.993762#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.994052#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.994383#011validation-auc:0.995742\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.994321#011validation-auc:0.995087\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.994507#011validation-auc:0.995742\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.994279#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.994879#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.994931#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.994848#011validation-auc:0.997052\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.995645#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.996059#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.996038#011validation-auc:0.997052\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.996121#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.996576#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.996638#011validation-auc:0.996725\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.996535#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.996535#011validation-auc:0.996397\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.996814#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[68]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[69]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[70]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[71]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[72]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[73]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[74]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[75]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[76]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[77]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[78]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[79]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[80]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[81]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[82]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[83]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[84]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[85]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[86]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[87]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[88]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[89]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[90]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[91]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[92]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[93]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[94]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[95]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[96]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[97]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[98]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\u001b[34m[99]#011train-auc:0.996793#011validation-auc:0.996069\u001b[0m\n",
      "\n",
      "2020-12-14 08:47:38 Training - Training image download completed. Training in progress.\n",
      "2020-12-14 08:48:09 Uploading - Uploading generated training model\n",
      "2020-12-14 08:48:09 Completed - Training job completed\n",
      "Training seconds: 82\n",
      "Billable seconds: 82\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(region, 'xgboost', '0.90-1')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m5.xlarge',\n",
    "                                    output_path=OUTPUT_PATH,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=2,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100,\n",
    "                        eval_metric='auc')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, \n",
    "         'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.deserializer = csv_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c285bc7d8409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv_serializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_serializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.Predictor at 0x7f8cea9d2128>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
      " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
      " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
      " ...\n",
      " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
      " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
      " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n",
      "split_array\n",
      "[array([[1.247e+01, 1.860e+01, 8.109e+01, ..., 1.015e-01, 3.014e-01,\n",
      "        8.750e-02],\n",
      "       [1.894e+01, 2.131e+01, 1.236e+02, ..., 1.789e-01, 2.551e-01,\n",
      "        6.589e-02],\n",
      "       [1.546e+01, 1.948e+01, 1.017e+02, ..., 1.514e-01, 2.837e-01,\n",
      "        8.019e-02],\n",
      "       ...,\n",
      "       [1.152e+01, 1.493e+01, 7.387e+01, ..., 9.608e-02, 2.664e-01,\n",
      "        7.809e-02],\n",
      "       [1.422e+01, 2.785e+01, 9.255e+01, ..., 8.219e-02, 1.890e-01,\n",
      "        7.796e-02],\n",
      "       [2.073e+01, 3.112e+01, 1.357e+02, ..., 1.659e-01, 2.868e-01,\n",
      "        8.218e-02]])]\n",
      "array\n",
      "[[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
      " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
      " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
      " ...\n",
      " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
      " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
      " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n",
      "predict\n",
      "[['0.9598382115364075', '0.010558008216321468', '0.009114286862313747', '0.9822686910629272', '0.9934383034706116', '0.0070849936455488205', '0.012838135473430157', '0.1544346809387207', '0.4938497543334961', '0.9901305437088013', '0.9524217844009399', '0.034033503383398056', '0.958427369594574', '0.09107600152492523', '0.9903035759925842', '0.011633651331067085', '0.9799379706382751', '0.9908438920974731', '0.9881733059883118', '0.016853760927915573', '0.9179869890213013', '0.9796687960624695', '0.0070849936455488205', '0.9697061777114868', '0.9525127410888672', '0.9534565806388855', '0.991462767124176', '0.9401124119758606', '0.9862333536148071', '0.0070849936455488205', '0.9536004066467285', '0.9920143485069275', '0.9656414985656738', '0.9799379706382751', '0.9835314750671387', '0.9864863157272339', '0.23486430943012238', '0.9799504280090332', '0.007198734674602747', '0.8881891369819641', '0.9886764287948608', '0.008604468777775764', '0.9872618317604065', '0.9891409873962402', '0.9380509853363037', '0.9125621318817139', '0.9902756214141846', '0.9415915608406067', '0.9258456826210022', '0.991462767124176', '0.005820632912218571', '0.0070849936455488205', '0.8956775665283203', '0.9378818869590759', '0.9900743365287781', '0.9865886569023132', '0.9919912219047546', '0.008604468777775764', '0.25054284930229187', '0.9920143485069275', '0.9862333536148071', '0.009126792661845684', '0.008604468777775764', '0.9417473673820496', '0.9835066795349121', '0.910651683807373', '0.0070849936455488205', '0.0070849936455488205', '0.9833049774169922', '0.989635169506073', '0.03459760919213295', '0.013569372706115246', '0.9865886569023132', '0.010854518041014671', '0.9427189230918884', '0.9683123230934143', '0.950414776802063', '0.7738574743270874', '0.9934383034706116', '0.9588545560836792', '0.015135567635297775', '0.9920143485069275', '0.5354583859443665', '0.010579010471701622', '0.1744917780160904', '0.067513108253479', '0.13482823967933655', '0.012838135473430157', '0.9497178792953491', '0.9911762475967407', '0.973507821559906', '0.7794488668441772', '0.9386498928070068', '0.9524217844009399', '0.9752137064933777', '0.9900743365287781', '0.012838135473430157', '0.009026133455336094', '0.9903035759925842', '0.010915076360106468', '0.021109072491526604', '0.9903035759925842', '0.04701581597328186', '0.011311023496091366', '0.9286944270133972', '0.9787369966506958', '0.9533824324607849', '0.026658086106181145', '0.6868545413017273', '0.9522725343704224', '0.02742859162390232', '0.9902562499046326', '0.7681744694709778', '0.005820632912218571']]\n",
      "done\n",
      "pred\n",
      "0.9598382115364075,0.010558008216321468,0.009114286862313747,0.9822686910629272,0.9934383034706116,0.0070849936455488205,0.012838135473430157,0.1544346809387207,0.4938497543334961,0.9901305437088013,0.9524217844009399,0.034033503383398056,0.958427369594574,0.09107600152492523,0.9903035759925842,0.011633651331067085,0.9799379706382751,0.9908438920974731,0.9881733059883118,0.016853760927915573,0.9179869890213013,0.9796687960624695,0.0070849936455488205,0.9697061777114868,0.9525127410888672,0.9534565806388855,0.991462767124176,0.9401124119758606,0.9862333536148071,0.0070849936455488205,0.9536004066467285,0.9920143485069275,0.9656414985656738,0.9799379706382751,0.9835314750671387,0.9864863157272339,0.23486430943012238,0.9799504280090332,0.007198734674602747,0.8881891369819641,0.9886764287948608,0.008604468777775764,0.9872618317604065,0.9891409873962402,0.9380509853363037,0.9125621318817139,0.9902756214141846,0.9415915608406067,0.9258456826210022,0.991462767124176,0.005820632912218571,0.0070849936455488205,0.8956775665283203,0.9378818869590759,0.9900743365287781,0.9865886569023132,0.9919912219047546,0.008604468777775764,0.25054284930229187,0.9920143485069275,0.9862333536148071,0.009126792661845684,0.008604468777775764,0.9417473673820496,0.9835066795349121,0.910651683807373,0.0070849936455488205,0.0070849936455488205,0.9833049774169922,0.989635169506073,0.03459760919213295,0.013569372706115246,0.9865886569023132,0.010854518041014671,0.9427189230918884,0.9683123230934143,0.950414776802063,0.7738574743270874,0.9934383034706116,0.9588545560836792,0.015135567635297775,0.9920143485069275,0.5354583859443665,0.010579010471701622,0.1744917780160904,0.067513108253479,0.13482823967933655,0.012838135473430157,0.9497178792953491,0.9911762475967407,0.973507821559906,0.7794488668441772,0.9386498928070068,0.9524217844009399,0.9752137064933777,0.9900743365287781,0.012838135473430157,0.009026133455336094,0.9903035759925842,0.010915076360106468,0.021109072491526604,0.9903035759925842,0.04701581597328186,0.011311023496091366,0.9286944270133972,0.9787369966506958,0.9533824324607849,0.026658086106181145,0.6868545413017273,0.9522725343704224,0.02742859162390232,0.9902562499046326,0.7681744694709778,0.005820632912218571\n"
     ]
    }
   ],
   "source": [
    "## Lets now run predictions on our test set and use it to create a table containing our outputs.\n",
    "import numpy as np\n",
    "\n",
    "def predict(data, model, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    print('split_array')\n",
    "    print(split_array)\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "#        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "        print('array')\n",
    "        print(array)\n",
    "        print('predict')\n",
    "        print(model.predict(array))\n",
    "        print('done')\n",
    "        print('pred')\n",
    "        pred = ','.join(model.predict(array)[0])\n",
    "        print(pred)\n",
    "        predictions += pred\n",
    "\n",
    "    return np.round(np.fromstring(predictions[1:], sep=','))\n",
    "\n",
    "## Generate predictions on the test set for the difference models\n",
    "print(test_data[list(test_data.columns)[1:]].values)\n",
    "\n",
    "predictions = predict(test_data[list(test_data.columns)[1:]].values, xgb_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating human review Workteam or Workforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A workforce is the group of workers that you have selected to label your dataset. You can choose either the Amazon Mechanical Turk workforce, a vendor-managed workforce, or you can create your own private workforce for human reviews. Whichever workforce type you choose, Amazon Augmented AI takes care of sending tasks to workers. \n",
    "\n",
    "When you use a private workforce, you also create work teams, a group of workers from your workforce that are assigned to Amazon Augmented AI human review tasks. You can have multiple work teams and can assign one or more work teams to each job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create your Workteam, visit the instructions here: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management.html\n",
    "\n",
    "After you have created your workteam, replace YOUR_WORKTEAM_ARN below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN = 'arn:aws:sagemaker:eu-central-1:835034110975:workteam/private-crowd/halag-team'#'YOUR_WORKTEAM_ARN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit: https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-permissions-security.html to add the necessary permissions to your role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Setup\n",
    "\n",
    "Here we are going to setup the rest of our clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker', region)\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon S3 client \n",
    "s3 = boto3.client('s3', region)\n",
    "\n",
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'fd-sagemaker-tabular-data-demo-' + timestamp\n",
    "\n",
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'ui-sagemaker-tabular-data-demo-' + timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Control Plane Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Human Task UI\n",
    "\n",
    "Create a human task UI resource, giving a UI template in liquid html. This template will be rendered to the human workers whenever human loop is required.\n",
    "\n",
    "For over 70 pre built UIs, check: https://github.com/aws-samples/amazon-a2i-sample-task-uis.\n",
    "\n",
    "We will use the following template to render both the test dataset, as well as the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<style>\n",
    "  table, tr, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    padding: 5px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<crowd-form>\n",
    "    <div>\n",
    "        <h1>Instructions</h1>\n",
    "        <p>Please review the predictions in the Predictions table based on the input data table below, and make corrections where appropriate. </p>\n",
    "        <p> Here are the labels: </p>\n",
    "        <p> 0: Benign </p>\n",
    "        <p> 1: Malignant </p>\n",
    "    </div>\n",
    "    <div>\n",
    "      <h3> Breast cancer dataset </h3>\n",
    "      <div id=\"my_table\"> {{ task.input.table | skip_autoescape }} </div>\n",
    "   </div>\n",
    "    <br>\n",
    "    <h1> Predictions Table </h1>\n",
    "    <table>\n",
    "      <tr>\n",
    "        <th>ROW NUMBER</th>\n",
    "        <th>MODEL PREDICTION</th>\n",
    "        <th>AGREE/DISAGREE WITH ML RATING?</th>\n",
    "        <th>YOUR PREDICTION</th>\n",
    "        <th>CHANGE REASON </th>\n",
    "      </tr>\n",
    "\n",
    "      {% for pair in task.input.Pairs %}\n",
    "\n",
    "        <tr>\n",
    "          <td>{{ pair.row }}</td>\n",
    "          <td><crowd-text-area name=\"predicted{{ forloop.index }}\" value=\"{{ pair.prediction }}\"></crowd-text-area></td>\n",
    "          <td>\n",
    "            <p>\n",
    "              <input type=\"radio\" id=\"agree{{ forloop.index }}\" name=\"rating{{ forloop.index }}\" value=\"agree\" required>\n",
    "              <label for=\"agree{{ forloop.index }}\">Agree</label>\n",
    "            </p>\n",
    "            <p>\n",
    "              <input type=\"radio\" id=\"disagree{{ forloop.index }}\" name=\"rating{{ forloop.index }}\" value=\"disagree\" required>\n",
    "              <label for=\"disagree{{ forloop.index }}\">Disagree</label>       \n",
    "            </p> \n",
    "          </td>\n",
    "          <td>\n",
    "            <p>\n",
    "            <input type=\"text\" name=\"True Prediction\" placeholder=\"Enter your Prediction\" />\n",
    "            </p>\n",
    "           </td>\n",
    "           <td>\n",
    "            <p>\n",
    "            <input type=\"text\" name=\"Change Reason\" placeholder=\"Explain why you changed the prediction\" />\n",
    "            </p>\n",
    "           </td>\n",
    "        </tr>\n",
    "\n",
    "      {% endfor %}\n",
    "\n",
    "    </table>\n",
    "</crowd-form>\n",
    "\"\"\"\n",
    "\n",
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker_client.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:eu-central-1:835034110975:human-task-ui/ui-sagemaker-tabular-data-demo-2020-12-14-10-25-10\n"
     ]
    }
   ],
   "source": [
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Flow Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to create a flow definition definition. Flow Definitions allow us to specify:\n",
    "\n",
    "* The workforce that your tasks will be sent to.\n",
    "* The instructions that your workforce will receive. This is called a worker task template.\n",
    "* The configuration of your worker tasks, including the number of workers that receive a task and time limits to complete tasks.\n",
    "* Where your output data will be stored.\n",
    "\n",
    "This demo is going to use the API, but you can optionally create this workflow definition in the console as well. \n",
    "\n",
    "For more details and instructions, see: https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workflow_definition_response = sagemaker_client.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn= role,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Make sure the labels are correct\",\n",
    "            \"TaskTitle\": \"tabular data a2i demo\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "Active\n",
      "Flow Definition is active\n"
     ]
    }
   ],
   "source": [
    "# Describe flow definition - status should be active\n",
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker_client.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Loops\n",
    "\n",
    "Now that we have setup our Flow Definition, we are ready to start the human loop to have the reviewers asynchronously review the outputs generated by our model. First we need to create a dictionary containing our model outputs, so we can load it dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'row': 'ROW_0', 'prediction': 1.0},\n",
       " {'row': 'ROW_1', 'prediction': 0.0},\n",
       " {'row': 'ROW_2', 'prediction': 0.0},\n",
       " {'row': 'ROW_3', 'prediction': 1.0},\n",
       " {'row': 'ROW_4', 'prediction': 1.0}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list = [{'row': \"ROW_{}\".format(x), 'prediction': predictions[x]} for x in range(5)]\n",
    "item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_content = {\"table\": test_data.reset_index().drop(columns = ['index', 'label']).head().to_html(), \n",
    "              'Pairs': item_list\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "humanLoopName = str(uuid.uuid4())\n",
    "\n",
    "start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(ip_content)\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 99d8d2a9-2732-4b07-882b-5e46dc7fadb9\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-eu-central-1-835034110975/a2i-results/fd-sagemaker-tabular-data-demo-2020-12-14-10-25-10/2020/12/14/10/37/09/99d8d2a9-2732-4b07-882b-5e46dc7fadb9/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "    \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait For Workers to Complete Task\n",
    "Since we are using private workteam, we should go to the labling UI to perform the inspection ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\n",
      "https://yz4f8v5gqv.labeling.eu-central-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker_client.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "    \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Task Results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i.stop_human_loop(HumanLoopName=humanLoopName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i.delete_human_loop(HumanLoopName=humanLoopName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
